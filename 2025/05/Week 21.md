# ðŸ“… Week 21 â€“ May 19â€“23, 2025

**Summary:**  
A week marked by significant industry developments and deep technical writing. Microsoft's announcement that VS Code would become an open-source AI editor on May 19th created ripple effects across the developer tools landscape, particularly impacting Cursor's positioning. I published two major technical pieces examining AI tokenization and the Cursor/VS Code dynamics while continuing to advance our internal AI initiatives.

**What I Did:**  
- Published "Why Your AI Outputs Are Wrong - The Hidden Impact of Tokenization" (May 20) â€“ a comprehensive analysis of how tokenization affects AI model performance, covering BPE, SentencePiece, and emerging approaches
- Researched and wrote "Cursor Faces Dev Backlash as VS Code Launches Open-Source AI Tool" (May 23) analyzing the developer community response to performance issues and Microsoft's strategic announcement  
- Monitored industry developments around AI developer tools, particularly the VS Code announcement and its implications for our internal tooling strategy
- Continued advancing AI Steering Committee initiatives and internal rollout planning
- Evaluated how external tool developments might affect our Cursor adoption strategy

**Result:**  
- Two significant technical publications that demonstrate deep understanding of AI tooling landscape and technical fundamentals
- Better positioned to make informed decisions about our internal AI tool strategy given the shifting competitive landscape
- Increased awareness of tokenization impacts on our AI implementations and prompt engineering approaches
- Clearer picture of risks and opportunities in the evolving AI developer tools space

**Reflection:**  
This week felt like a pivotal moment in the AI tools landscape. Microsoft's move to open-source VS Code's AI capabilities isn't just a feature announcementâ€”it's a strategic response to the exact transparency and trust issues I've been observing in tools like Cursor. The timing of writing about both tokenization fundamentals and the Cursor situation gave me valuable perspective on how technical depth and community trust intersect.

The tokenization piece reinforced how much invisible complexity affects AI system performance. Understanding these fundamentals becomes more critical as we expand our internal AI usageâ€”especially when debugging unexpected behaviors or optimizing costs. It's knowledge that extends beyond just using tools to actually building reliable AI-integrated systems.

The industry turbulence around Cursor also validates our cautious, measured approach to AI tool adoption. Rather than going all-in on any single platform, we've been building understanding and maintaining flexibility. With Microsoft making such a significant play, and other tools like Claude Code emerging, this patience may serve us well.

Moving forward, I want to apply the tokenization insights to improve our prompt engineering and better predict when we might hit context limits. The broader tools landscape shift also suggests we should accelerate our evaluation of alternatives to ensure we're not overly dependent on any single vendor.